{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f168103-cb1e-4b64-bb97-8751efbc767e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Weather forecasting with PySpark\n",
    "## Big Data Computing final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f9d64b0-bcaa-48c0-b8a6-05cb6147892c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Define some global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94b551c2-61ce-4055-bd75-9cf63c685f05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH: str = 'dbfs:/bigdata_proj/datasets/historical-hourly-weather/'\n",
    "MODELS_PATH: str = 'dbfs:/bigdata_proj/models/historical-hourly-weather/'\n",
    "\n",
    "RANDOM_SEED: int = 42\n",
    "  \n",
    "SLOW_OPERATIONS: bool = True\n",
    "  \n",
    "# True to save the computation of datataset preprocessing, fitted pipelines and trained models to the filesystem\n",
    "SAVE_COMPUTATIONS: bool = True\n",
    "  \n",
    "# True to load the sampled dataset from the filesystem, False to compute it from the raw one\n",
    "LOAD_SAMPLED_DATASET: bool = True\n",
    "SAMPLED_DATASET_PATH: str = f'{DATASET_PATH}aggregated_sampled_weather_measurements.csv'\n",
    "  \n",
    "# True to load the encoding pipeline from the filesystem, False to compute it from scratch\n",
    "LOAD_ECONDING_PIPELINE: bool = True\n",
    "ENCODING_PIPELINE_PATH: str = f'{MODELS_PATH}data_encoder'\n",
    "\n",
    "# True to load pretrained models from the filesystem, False to compute them from scratch\n",
    "LOAD_PRETRAINED_MODELS: bool = True\n",
    "RANDOM_FOREST_MODEL_PATH: str = f'{MODELS_PATH}rnd_forest'\n",
    "RANDOM_FOREST_CROSS_VALIDATION_MODEL_PATH: str = f'{MODELS_PATH}rnd_forest_cv'\n",
    "LOGISTIC_REGRESSION_CROSS_VALIDATION_MODEL_PATH: str = f'{MODELS_PATH}log_reg_cv'\n",
    "\n",
    "# necessary due to DataBricks community edition limits (training on a dataframe larger than this threshold causes an Internal Server Error)\n",
    "MAX_TRAIN_SIZE: int = 999_999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d95064a1-afae-4596-9ce1-3f7c617b2cf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Import PySpark packages and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78bd20fe-eb60-4c47-9bda-ccf358d08ffb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11b2fecb-a80c-4202-83bd-185690f85764",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Dataset initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8935700-3499-4982-9208-e74a707e690e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Download the dataset\n",
    "Original source: [kaggle.com/selfishgene/historical-hourly-weather-data](https://www.kaggle.com/selfishgene/historical-hourly-weather-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af85f425-ccd3-409a-8884-cf45053a5ab1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 17:05:24 URL:https://raw.githubusercontent.com/andrea-gasparini/big-data-weather-forecasting/master/dataset/historical-hourly-weather-dataset.zip [12655281/12655281] -> \"/tmp/dataset.zip\" [1]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/dataset.zip\n   creating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/\n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/._committed_7616641238230246128.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00000-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5515-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00006-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5521-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00002-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5517-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00004-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5519-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00003-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5518-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/_committed_7616641238230246128  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/_committed_vacuum6920010656788597249  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00005-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5520-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00002-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5517-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/_started_5785058191842647654  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00001-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5516-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/_committed_777980178201020908  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/_committed_5785058191842647654  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/._committed_5785058191842647654.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00001-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5516-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00003-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5518-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00007-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5522-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00006-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5521-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/._started_5785058191842647654.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/._committed_777980178201020908.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00000-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5515-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00007-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5522-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/.part-00005-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5520-1-c000.csv.crc  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/part-00004-tid-5785058191842647654-99694b27-5637-4d82-97fd-79413e3b2b1a-5519-1-c000.csv  \n  inflating: /tmp/dataset/aggregated_sampled_weather_measurements.csv/._committed_vacuum6920010656788597249.crc  \n  inflating: /tmp/dataset/city_attributes.csv  \n  inflating: /tmp/dataset/humidity.csv  \n  inflating: /tmp/dataset/pressure.csv  \n  inflating: /tmp/dataset/temperature.csv  \n  inflating: /tmp/dataset/weather_description.csv  \n  inflating: /tmp/dataset/wind_direction.csv  \n  inflating: /tmp/dataset/wind_speed.csv  \n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "wget --no-verbose https://github.com/andrea-gasparini/big-data-weather-forecasting/raw/master/dataset/historical-hourly-weather-dataset.zip -O /tmp/dataset.zip\n",
    "unzip -u /tmp/dataset.zip -d /tmp/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54686efa-a033-4197-a7e0-9559fe961d48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Move the dataset from Databricks local driver node's file system to DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cce2f5a-7a72-4e19-945d-78d45f664546",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for file in dbutils.fs.ls('file:/tmp/dataset'):\n",
    "    dbutils.fs.mv(file.path, f'{DATASET_PATH}{file.name}', recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a9ccdc-b123-4083-85ce-c679b186b645",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/aggregated_sampled_weather_measurements.csv/</td><td>aggregated_sampled_weather_measurements.csv/</td><td>0</td><td>1710607244000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/city_attributes.csv</td><td>city_attributes.csv</td><td>1614</td><td>1710608726000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/humidity.csv</td><td>humidity.csv</td><td>9075077</td><td>1710608725000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/pressure.csv</td><td>pressure.csv</td><td>12155911</td><td>1710608726000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/temperature.csv</td><td>temperature.csv</td><td>13971171</td><td>1710608726000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/weather_description.csv</td><td>weather_description.csv</td><td>21858089</td><td>1710608728000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/wind_direction.csv</td><td>wind_direction.csv</td><td>10171003</td><td>1710608726000</td></tr><tr><td>dbfs:/bigdata_proj/datasets/historical-hourly-weather/wind_speed.csv</td><td>wind_speed.csv</td><td>7457531</td><td>1710608728000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/aggregated_sampled_weather_measurements.csv/",
         "aggregated_sampled_weather_measurements.csv/",
         0,
         1710607244000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/city_attributes.csv",
         "city_attributes.csv",
         1614,
         1710608726000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/humidity.csv",
         "humidity.csv",
         9075077,
         1710608725000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/pressure.csv",
         "pressure.csv",
         12155911,
         1710608726000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/temperature.csv",
         "temperature.csv",
         13971171,
         1710608726000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/weather_description.csv",
         "weather_description.csv",
         21858089,
         1710608728000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/wind_direction.csv",
         "wind_direction.csv",
         10171003,
         1710608726000
        ],
        [
         "dbfs:/bigdata_proj/datasets/historical-hourly-weather/wind_speed.csv",
         "wind_speed.csv",
         7457531,
         1710608728000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /bigdata_proj/datasets/historical-hourly-weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2b0f8a5-d709-4dfa-b734-f4952f5452f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Load dataset into Spark DataFrame objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ce1bbf6-28aa-4199-904b-ebb5d4f236c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Dataset shape and schema\n",
    "The raw dataset downloaded from kaggle is composed of 7 different `.csv` files:\n",
    "- `city_attributes.csv` contains geographical information about the different cities for which there are weather measurements\n",
    "- `weather_description.csv` contains the textual description of the weather conditions, where each column refers to a different city and each row refers to a specific `datetime` in which the weather condition occurred\n",
    "- Each one of the other 5 csv follows the same structure as `weather_description.csv` and contains the measurements of the following metrics: `humidity`,  `pressure`, `temperature`, `wind_direction`, `wind_speed`\n",
    "\n",
    "Except for `city_attributes.csv`, all the other files contains about **45.000** records of hourly weather measurements, that multiplied by the **36** cities results in approximately **1.500.000** records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18a1bfb4-dc11-4ab2-9f4c-2a6ad73046d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# rest of your code\n",
    "weather_conditions_df = spark.read.csv(f'{DATASET_PATH}weather_description.csv', header=True, inferSchema=True)\n",
    "humidity_df = spark.read.csv(f'{DATASET_PATH}humidity.csv', header=True, inferSchema=True)\n",
    "pressure_df = spark.read.csv(f'{DATASET_PATH}pressure.csv', header=True, inferSchema=True)\n",
    "temperature_df = spark.read.csv(f'{DATASET_PATH}temperature.csv', header=True, inferSchema=True)\n",
    "city_attributes_df = spark.read.csv(f'{DATASET_PATH}city_attributes.csv', header=True, inferSchema=True)\n",
    "wind_direction_df = spark.read.csv(f'{DATASET_PATH}wind_direction.csv', header=True, inferSchema=True)\n",
    "wind_speed_df = spark.read.csv(f'{DATASET_PATH}wind_speed.csv', header=True, inferSchema=True)"
   ]
  }]
}
